{
  
    
        "post0": {
            "title": "Compute Velocity along Z",
            "content": "import os import glob import numpy as np from math import sqrt, log import matplotlib.pyplot as plt import matplotlib.patches as mpatches from collections import OrderedDict linestyles = OrderedDict( [(&#39;solid&#39;, (0, ())), (&#39;loosely dotted&#39;, (0, (1, 10))), (&#39;dotted&#39;, (0, (1, 5))), (&#39;densely dotted&#39;, (0, (1, 1))), (&#39;loosely dashed&#39;, (0, (5, 10))), (&#39;dashed&#39;, (0, (5, 5))), (&#39;densely dashed&#39;, (0, (5, 1))), (&#39;loosely dashdotted&#39;, (0, (3, 10, 1, 10))), (&#39;dashdotted&#39;, (0, (3, 5, 1, 5))), (&#39;densely dashdotted&#39;, (0, (3, 1, 1, 1))), (&#39;loosely dashdotdotted&#39;, (0, (3, 10, 1, 10, 1, 10))), (&#39;dashdotdotted&#39;, (0, (3, 5, 1, 5, 1, 5))), (&#39;densely dashdotdotted&#39;, (0, (3, 1, 1, 1, 1, 1)))]) def ustar(uref, zref, z0): &quot;&quot;&quot;Calculate friction velocity for a neutral ABL logartithmic profile.&quot;&quot;&quot; return KARMAN * uref / log((zref + z0) / z0) def u_z(z, z0, zref, uref): frac = ustar(uref, zref, z0)/ KARMAN _ = frac * np.log(z/ z0) return _.reshape(-1, 1) . UREF = 3 ZREF = 5 KARMAN = 0.4 Cmu = 0.09 roughnessList = [0.001, 0.03,0.10, 0.25, 0.50, 1, 2] Z = np.arange(1, 100, 2) U_Z = np.zeros((Z.shape[0],len(roughnessList))) for i, Z0 in enumerate(roughnessList): U_Z[:, i] = u_z(Z, Z0, ZREF, UREF)[:, 0] U_Z.shape, Z.shape . ((50, 7), (50,)) . linestyles.keys() . odict_keys([&#39;solid&#39;, &#39;loosely dotted&#39;, &#39;dotted&#39;, &#39;densely dotted&#39;, &#39;loosely dashed&#39;, &#39;dashed&#39;, &#39;densely dashed&#39;, &#39;loosely dashdotted&#39;, &#39;dashdotted&#39;, &#39;densely dashdotted&#39;, &#39;loosely dashdotdotted&#39;, &#39;dashdotdotted&#39;, &#39;densely dashdotdotted&#39;]) . fig, (ax1) = plt.subplots(1, 1, figsize=(10,10)) ax1.grid(True, which = &quot;major&quot;, axis = &quot;both&quot;) ln_styles = [&#39;solid&#39;, &#39;loosely dotted&#39;, &#39;dotted&#39;, &#39;densely dotted&#39;, &#39;loosely dashed&#39;, &#39;dashed&#39;, &#39;densely dashed&#39;,&#39;loosely dashdotted&#39;, &#39;dashdotted&#39;, &#39;densely dashdotted&#39;, &#39;loosely dashdotdotted&#39;, &#39;dashdotdotted&#39;,&#39;densely dashdotdotted&#39;] for j in range(U_Z.shape[1]): ax1.plot(U_Z[:, j], Z, label=&#39;z0 = &#39;+str(roughnessList[j])+&#39; m&#39;, color = &quot;k&quot;, ls = linestyles[ln_styles[j]]) # add an ellipse patches = [] ellipse = mpatches.Rectangle((-2, 0), 2, 4,color = &#39;r&#39;) #patches.append(ellipse) ax1.add_patch(ellipse) ax1.legend(loc=&#39;upper left&#39;, shadow=True) ax1.set_ylabel(&#39;Height above ground [m]&#39;) ax1.set_title(&quot;Wind speed [m/s]&quot;) ax1.set_ylim((0,100)) ax1.set_xlim((-2,10)) ax1.annotate(&#39;Model breaks for high roughness&#39;, xy=(-1.0, 3.5), xytext=(-1.0, 15), arrowprops=dict(facecolor=&#39;red&#39;, edgecolor=&#39;red&#39;, shrink=0.05), color = &#39;red&#39;) #plt.show() plt.savefig(&quot;vel_Uz.png&quot;, dpi = 300) .",
            "url": "https://simsisim.github.io/sims-blog/openfoam/2021/03/08/vel_Uz.html",
            "relUrl": "/openfoam/2021/03/08/vel_Uz.html",
            "date": " • Mar 8, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Compute Velocity along Z",
            "content": "import os import glob import numpy as np from math import sqrt, log import matplotlib.pyplot as plt import matplotlib.patches as mpatches from collections import OrderedDict linestyles = OrderedDict( [(&#39;solid&#39;, (0, ())), (&#39;loosely dotted&#39;, (0, (1, 10))), (&#39;dotted&#39;, (0, (1, 5))), (&#39;densely dotted&#39;, (0, (1, 1))), (&#39;loosely dashed&#39;, (0, (5, 10))), (&#39;dashed&#39;, (0, (5, 5))), (&#39;densely dashed&#39;, (0, (5, 1))), (&#39;loosely dashdotted&#39;, (0, (3, 10, 1, 10))), (&#39;dashdotted&#39;, (0, (3, 5, 1, 5))), (&#39;densely dashdotted&#39;, (0, (3, 1, 1, 1))), (&#39;loosely dashdotdotted&#39;, (0, (3, 10, 1, 10, 1, 10))), (&#39;dashdotdotted&#39;, (0, (3, 5, 1, 5, 1, 5))), (&#39;densely dashdotdotted&#39;, (0, (3, 1, 1, 1, 1, 1)))]) def ustar(uref, zref, z0): &quot;&quot;&quot;Calculate friction velocity for a neutral ABL logartithmic profile.&quot;&quot;&quot; return KARMAN * uref / log((zref + z0) / z0) def u_z(z, z0, zref, uref): frac = ustar(uref, zref, z0)/ KARMAN _ = frac * np.log(z/ z0) return _.reshape(-1, 1) . UREF = 3 ZREF = 5 KARMAN = 0.4 Cmu = 0.09 roughnessList = [0.001, 0.03,0.10, 0.25, 0.50, 1, 2] Z = np.arange(1, 100, 2) U_Z = np.zeros((Z.shape[0],len(roughnessList))) for i, Z0 in enumerate(roughnessList): U_Z[:, i] = u_z(Z, Z0, ZREF, UREF)[:, 0] U_Z.shape, Z.shape . ((50, 7), (50,)) . linestyles.keys() . odict_keys([&#39;solid&#39;, &#39;loosely dotted&#39;, &#39;dotted&#39;, &#39;densely dotted&#39;, &#39;loosely dashed&#39;, &#39;dashed&#39;, &#39;densely dashed&#39;, &#39;loosely dashdotted&#39;, &#39;dashdotted&#39;, &#39;densely dashdotted&#39;, &#39;loosely dashdotdotted&#39;, &#39;dashdotdotted&#39;, &#39;densely dashdotdotted&#39;]) . fig, (ax1) = plt.subplots(1, 1, figsize=(10,10)) ax1.grid(True, which = &quot;major&quot;, axis = &quot;both&quot;) ln_styles = [&#39;solid&#39;, &#39;loosely dotted&#39;, &#39;dotted&#39;, &#39;densely dotted&#39;, &#39;loosely dashed&#39;, &#39;dashed&#39;, &#39;densely dashed&#39;,&#39;loosely dashdotted&#39;, &#39;dashdotted&#39;, &#39;densely dashdotted&#39;, &#39;loosely dashdotdotted&#39;, &#39;dashdotdotted&#39;,&#39;densely dashdotdotted&#39;] for j in range(U_Z.shape[1]): ax1.plot(U_Z[:, j], Z, label=&#39;z0 = &#39;+str(roughnessList[j])+&#39; m&#39;, color = &quot;k&quot;, ls = linestyles[ln_styles[j]]) # add an ellipse patches = [] ellipse = mpatches.Rectangle((-2, 0), 2, 4,color = &#39;r&#39;) #patches.append(ellipse) ax1.add_patch(ellipse) ax1.legend(loc=&#39;upper left&#39;, shadow=True) ax1.set_ylabel(&#39;Height above ground [m]&#39;) ax1.set_title(&quot;Wind speed [m/s]&quot;) ax1.set_ylim((0,100)) ax1.set_xlim((-2,10)) ax1.annotate(&#39;Model breaks for high roughness&#39;, xy=(-1.0, 3.5), xytext=(-1.0, 15), arrowprops=dict(facecolor=&#39;red&#39;, edgecolor=&#39;red&#39;, shrink=0.05), color = &#39;red&#39;) #plt.show() plt.savefig(&quot;vel_Uz.png&quot;, dpi = 300) .",
            "url": "https://simsisim.github.io/sims-blog/openfoam/2021/03/08/_vel_Uz.html",
            "relUrl": "/openfoam/2021/03/08/_vel_Uz.html",
            "date": " • Mar 8, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Download data in GoogleColab",
            "content": "from google.colab import drive drive.mount(&#39;/content/gdrive&#39;, force_remount = &quot;True&quot;) root_path = &#39;gdrive/My Drive/sims-data/malaria/&#39; #change dir to your project folder . Mounted at /content/gdrive . !pwd import os os.chdir(&quot;/content/gdrive/My Drive/sims-data/malaria/&quot;) !pwd . shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected pwd: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected /content/gdrive/My Drive/sims-data/malaria . 1. Download files directly in GoogleColab . !wget -P &#39;/content/gdrive/My Drive/sims-data/malaria/&#39; &#39;ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip&#39; . --2020-12-30 09:32:01-- ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip =&gt; ‘/content/gdrive/My Drive/sims-data/malaria/cell_images.zip’ Resolving lhcftp.nlm.nih.gov (lhcftp.nlm.nih.gov)... 130.14.55.35, 2607:f220:41e:7055::35 Connecting to lhcftp.nlm.nih.gov (lhcftp.nlm.nih.gov)|130.14.55.35|:21... connected. Logging in as anonymous ... Logged in! ==&gt; SYST ... done. ==&gt; PWD ... done. ==&gt; TYPE I ... done. ==&gt; CWD (1) /Open-Access-Datasets/Malaria ... done. ==&gt; SIZE cell_images.zip ... 353452851 ==&gt; PASV ... done. ==&gt; RETR cell_images.zip ... done. Length: 353452851 (337M) (unauthoritative) cell_images.zip 100%[===================&gt;] 337.08M 41.4MB/s in 8.8s 2020-12-30 09:32:11 (38.1 MB/s) - ‘/content/gdrive/My Drive/sims-data/malaria/cell_images.zip’ saved [353452851] . !ls . cell_images.zip . !pwd . /content/gdrive/My Drive/sims-data/malaria . ! rm -R &quot;/content/gdrive/My Drive/sims-data/malaria/cell_images/&quot; . 2. Unzip folder in GoogleColab . Unzipping in GoogleColab is painfully slow. It is faster to download data locally and load it unzipped in GoogleColab. | . !unzip -q file[.zip] -d [exdir] . -q suppress the printing of the file names being extracted . -d [exdir] optional directory to which to extract file . !unzip -q &quot;cell_images.zip&quot; . 3. Check size of folder in GoogleColab . ! du -sh &quot;/content/gdrive/&quot; . 8.0G /content/gdrive/ . 4. GitClone a GitHub repository in GoogleDrive . from google.colab import drive drive.mount(&#39;/content/gdrive&#39;, force_remount = &quot;True&quot;) root_path = &#39;gdrive/My Drive/&#39; #change dir to your project folder !pwd import os os.chdir(root_path) !pwd . Mounted at /content/gdrive /content /content/gdrive/My Drive . ! git clone https://github.com/simsisim/sims-data.git . Cloning into &#39;sims-data&#39;... remote: Enumerating objects: 27566, done. remote: Total 27566 (delta 0), reused 0 (delta 0), pack-reused 27566 Receiving objects: 100% (27566/27566), 331.64 MiB | 12.95 MiB/s, done. Checking out files: 100% (27560/27560), done. . . . References . https://medium.com/@satyajitghana7/working-with-huge-datasets-800k-files-in-google-colab-and-google-drive-bcb175c79477 .",
            "url": "https://simsisim.github.io/sims-blog/commands/googlecolab/2021/03/08/_GoogleColab_downloadData.html",
            "relUrl": "/commands/googlecolab/2021/03/08/_GoogleColab_downloadData.html",
            "date": " • Mar 8, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Usage of openFoam in Colab",
            "content": "1. Install openFoam . %%bash sh -c &quot;wget -O - http://dl.openfoam.org/gpg.key | apt-key add -&quot; add-apt-repository http://dl.openfoam.org/ubuntu apt-get update apt-get -y install openfoam6 . OK Hit:1 http://dl.openfoam.org/ubuntu bionic InRelease Hit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease Hit:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease Hit:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease Hit:9 http://security.ubuntu.com/ubuntu bionic-security InRelease Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 InRelease Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 InRelease Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 Release Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 Release Reading package lists... Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:3 http://dl.openfoam.org/ubuntu bionic InRelease Hit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease Hit:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease Hit:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease Hit:9 http://security.ubuntu.com/ubuntu bionic-security InRelease Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 InRelease Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 InRelease Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 Release Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 Release Reading package lists... Reading package lists... Building dependency tree... Reading state information... openfoam6 is already the newest version (20190620). 0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded. . --2021-02-09 11:36:09-- http://dl.openfoam.org/gpg.key Resolving dl.openfoam.org (dl.openfoam.org)... 35.179.33.128 Connecting to dl.openfoam.org (dl.openfoam.org)|35.179.33.128|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 1710 (1.7K) [application/pgp-keys] Saving to: ‘STDOUT’ 0K . 100% 465M=0s 2021-02-09 11:36:09 (465 MB/s) - written to stdout [1710/1710] Warning: apt-key output should not be parsed (stdout is not a terminal) . 2. Copy the cavitation tutorial to the current directory . %%bash . /opt/openfoam6/etc/bashrc cp -r $FOAM_TUTORIALS/incompressible/icoFoam/cavity/cavity ./ . 3. Calculation execution . %%bash . /opt/openfoam6/etc/bashrc cd ./cavity blockMesh &gt;log.blockMesh 2&gt;&amp;1 icoFoam &gt;log.icoFoam 2&gt;&amp;1 ls . 0 0.1 0.2 0.3 0.4 0.5 constant log.blockMesh log.icoFoam system . 4. Zip and download calculation. . %%bash zip -r cavity.zip ./cavity . adding: cavity/ (stored 0%) adding: cavity/0.1/ (stored 0%) adding: cavity/0.1/p (deflated 57%) adding: cavity/0.1/phi (deflated 63%) adding: cavity/0.1/U (deflated 63%) adding: cavity/0.1/uniform/ (stored 0%) adding: cavity/0.1/uniform/time (deflated 63%) adding: cavity/0.3/ (stored 0%) adding: cavity/0.3/p (deflated 56%) adding: cavity/0.3/phi (deflated 63%) adding: cavity/0.3/U (deflated 63%) adding: cavity/0.3/uniform/ (stored 0%) adding: cavity/0.3/uniform/time (deflated 63%) adding: cavity/0.5/ (stored 0%) adding: cavity/0.5/p (deflated 57%) adding: cavity/0.5/phi (deflated 63%) adding: cavity/0.5/U (deflated 63%) adding: cavity/0.5/uniform/ (stored 0%) adding: cavity/0.5/uniform/time (deflated 63%) adding: cavity/log.blockMesh (deflated 57%) adding: cavity/0.4/ (stored 0%) adding: cavity/0.4/p (deflated 57%) adding: cavity/0.4/phi (deflated 63%) adding: cavity/0.4/U (deflated 63%) adding: cavity/0.4/uniform/ (stored 0%) adding: cavity/0.4/uniform/time (deflated 63%) adding: cavity/system/ (stored 0%) adding: cavity/system/controlDict (deflated 61%) adding: cavity/system/blockMeshDict (deflated 64%) adding: cavity/system/fvSolution (deflated 64%) adding: cavity/system/fvSchemes (deflated 66%) adding: cavity/0.2/ (stored 0%) adding: cavity/0.2/p (deflated 57%) adding: cavity/0.2/phi (deflated 63%) adding: cavity/0.2/U (deflated 63%) adding: cavity/0.2/uniform/ (stored 0%) adding: cavity/0.2/uniform/time (deflated 63%) adding: cavity/log.icoFoam (deflated 87%) adding: cavity/constant/ (stored 0%) adding: cavity/constant/transportProperties (deflated 61%) adding: cavity/constant/polyMesh/ (stored 0%) adding: cavity/constant/polyMesh/boundary (deflated 67%) adding: cavity/constant/polyMesh/points (deflated 87%) adding: cavity/constant/polyMesh/faces (deflated 64%) adding: cavity/constant/polyMesh/neighbour (deflated 59%) adding: cavity/constant/polyMesh/owner (deflated 76%) adding: cavity/0/ (stored 0%) adding: cavity/0/p (deflated 63%) adding: cavity/0/U (deflated 63%) . from google.colab import files files.download(&#39;cavity.zip&#39;) .",
            "url": "https://simsisim.github.io/sims-blog/openfoam/2021/03/08/_DrawShapes.html",
            "relUrl": "/openfoam/2021/03/08/_DrawShapes.html",
            "date": " • Mar 8, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Usage of openFoam in Colab",
            "content": "1. Install openFoam . %%bash sh -c &quot;wget -O - http://dl.openfoam.org/gpg.key | apt-key add -&quot; add-apt-repository http://dl.openfoam.org/ubuntu apt-get update apt-get -y install openfoam6 . OK Hit:1 http://dl.openfoam.org/ubuntu bionic InRelease Hit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease Hit:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease Hit:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease Hit:9 http://security.ubuntu.com/ubuntu bionic-security InRelease Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 InRelease Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 InRelease Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 Release Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 Release Reading package lists... Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:3 http://dl.openfoam.org/ubuntu bionic InRelease Hit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease Hit:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease Hit:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease Hit:9 http://security.ubuntu.com/ubuntu bionic-security InRelease Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 InRelease Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 InRelease Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 Release Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 Release Reading package lists... Reading package lists... Building dependency tree... Reading state information... openfoam6 is already the newest version (20190620). 0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded. . --2021-02-09 11:36:09-- http://dl.openfoam.org/gpg.key Resolving dl.openfoam.org (dl.openfoam.org)... 35.179.33.128 Connecting to dl.openfoam.org (dl.openfoam.org)|35.179.33.128|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 1710 (1.7K) [application/pgp-keys] Saving to: ‘STDOUT’ 0K . 100% 465M=0s 2021-02-09 11:36:09 (465 MB/s) - written to stdout [1710/1710] Warning: apt-key output should not be parsed (stdout is not a terminal) . 2. Copy the cavitation tutorial to the current directory . %%bash . /opt/openfoam6/etc/bashrc cp -r $FOAM_TUTORIALS/incompressible/icoFoam/cavity/cavity ./ . 3. Calculation execution . %%bash . /opt/openfoam6/etc/bashrc cd ./cavity blockMesh &gt;log.blockMesh 2&gt;&amp;1 icoFoam &gt;log.icoFoam 2&gt;&amp;1 ls . 0 0.1 0.2 0.3 0.4 0.5 constant log.blockMesh log.icoFoam system . 4. Zip and download calculation. . %%bash zip -r cavity.zip ./cavity . adding: cavity/ (stored 0%) adding: cavity/0.1/ (stored 0%) adding: cavity/0.1/p (deflated 57%) adding: cavity/0.1/phi (deflated 63%) adding: cavity/0.1/U (deflated 63%) adding: cavity/0.1/uniform/ (stored 0%) adding: cavity/0.1/uniform/time (deflated 63%) adding: cavity/0.3/ (stored 0%) adding: cavity/0.3/p (deflated 56%) adding: cavity/0.3/phi (deflated 63%) adding: cavity/0.3/U (deflated 63%) adding: cavity/0.3/uniform/ (stored 0%) adding: cavity/0.3/uniform/time (deflated 63%) adding: cavity/0.5/ (stored 0%) adding: cavity/0.5/p (deflated 57%) adding: cavity/0.5/phi (deflated 63%) adding: cavity/0.5/U (deflated 63%) adding: cavity/0.5/uniform/ (stored 0%) adding: cavity/0.5/uniform/time (deflated 63%) adding: cavity/log.blockMesh (deflated 57%) adding: cavity/0.4/ (stored 0%) adding: cavity/0.4/p (deflated 57%) adding: cavity/0.4/phi (deflated 63%) adding: cavity/0.4/U (deflated 63%) adding: cavity/0.4/uniform/ (stored 0%) adding: cavity/0.4/uniform/time (deflated 63%) adding: cavity/system/ (stored 0%) adding: cavity/system/controlDict (deflated 61%) adding: cavity/system/blockMeshDict (deflated 64%) adding: cavity/system/fvSolution (deflated 64%) adding: cavity/system/fvSchemes (deflated 66%) adding: cavity/0.2/ (stored 0%) adding: cavity/0.2/p (deflated 57%) adding: cavity/0.2/phi (deflated 63%) adding: cavity/0.2/U (deflated 63%) adding: cavity/0.2/uniform/ (stored 0%) adding: cavity/0.2/uniform/time (deflated 63%) adding: cavity/log.icoFoam (deflated 87%) adding: cavity/constant/ (stored 0%) adding: cavity/constant/transportProperties (deflated 61%) adding: cavity/constant/polyMesh/ (stored 0%) adding: cavity/constant/polyMesh/boundary (deflated 67%) adding: cavity/constant/polyMesh/points (deflated 87%) adding: cavity/constant/polyMesh/faces (deflated 64%) adding: cavity/constant/polyMesh/neighbour (deflated 59%) adding: cavity/constant/polyMesh/owner (deflated 76%) adding: cavity/0/ (stored 0%) adding: cavity/0/p (deflated 63%) adding: cavity/0/U (deflated 63%) . from google.colab import files files.download(&#39;cavity.zip&#39;) .",
            "url": "https://simsisim.github.io/sims-blog/openfoam/2021/02/09/openFoam_installation.html",
            "relUrl": "/openfoam/2021/02/09/openFoam_installation.html",
            "date": " • Feb 9, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Draw Shapes in Matplotlib",
            "content": "1. Install openFoam . import numpy as np import matplotlib.pyplot as plt import matplotlib.patches as mpatches #from matplotlib.patches import Polygon, Circle, Rectangle, Wedge . fig, (ax1) = plt.subplots(1, 1, figsize =(7, 7)) ax1.patches.append(mpatches.Circle([0.2, 0.8], 0.05, transform=fig.transFigure)) ax1.patches.append(mpatches.Rectangle((0.15, 0.58), 0.15, 0.15, transform=fig.transFigure)) ax1.patches.append(mpatches.Rectangle((0.15, 0.45), 0.20, 0.10, transform=fig.transFigure)) y = np.array([[0.15,0.35], [0.4,0.35], [0.15,0.42]]) ax1.patches.append(mpatches.Polygon(y, transform=fig.transFigure)) y = np.array([[0.20,0.20], [0.4,0.20], [0.5,0.32], [0.13, 0.30], [0.20,0.20]]) ax1.patches.append(mpatches.Polygon(y, transform=fig.transFigure)) y = np.array([[0.10,0.20], [0.4,0.20], [0.5,0.32], [0.13, 0.30], [0.20,0.20]]) ax1.patches.append(mpatches.Polygon(y, transform=fig.transFigure)) ax1.patches.append(mpatches.Rectangle((0.15, 0.15), 0.20, 0.025, transform=fig.transFigure)) # combinations ax1.patches.append(mpatches.Rectangle((0.65, 0.62), 0.15, 0.15, transform=fig.transFigure)) ax1.patches.append(mpatches.Circle([0.75, 0.8], 0.05, transform=fig.transFigure)) ax1.patches.append(mpatches.Circle([0.75, 0.45], 0.04, transform=fig.transFigure)) ax1.patches.append(mpatches.Circle([0.75, 0.50], 0.05, transform=fig.transFigure)) ax1.patches.append(mpatches.Circle([0.70, 0.50], 0.05, transform=fig.transFigure)) y = np.array([[0.65,0.15], [0.75,0.15], [0.65,0.4]]) ax1.patches.append(mpatches.Polygon(y, transform=fig.transFigure)) ax1.patches.append(mpatches.Circle([0.70, 0.30], 0.05, transform=fig.transFigure)) ax1.patches.append(mpatches.Rectangle((0.65, 0.2), 0.20, 0.025, transform=fig.transFigure)) #plt.axis(&#39;off&#39;) plt.xticks([]) plt.yticks([]) plt.savefig(&quot;shapes.png&quot;, dpi = 300) . fig, (ax1) = plt.subplots(1, 1,figsize = (7,7)) ax1.set_xlim(0,1) ax1.set_ylim(0,1) ax1.patches.append(mpatches.Rectangle((0.23, 0.4), 0.55, 0.3, transform=fig.transFigure, edgecolor = &#39;k&#39;, facecolor = &quot;None&quot;, lw = 2)) y = np.array([[0.40,0.45], [0.50,0.45], [0.45,0.4]]) #ax1.patches.append(mpatches.Polygon(y, transform=fig.transFigure)) ax1.patches.append(mpatches.Circle([0.45, 0.55], 0.05, transform=fig.transFigure)) ax1.patches.append(mpatches.Rectangle([0.45, 0.55], 0.10,0.10, transform=fig.transFigure)) #ax1.patches.append(mpatches.Rectangle((0.4, 0.4), 0.20, 0.025, transform=fig.transFigure)) y_list = [0.4, 0.50, 0.60, 0.70] for _, y in enumerate(y_list): ax1.arrow(0.135, y, 0.115, 0, length_includes_head=True, head_width=0.03, head_length=0.02) #ax1.arrow(0.85, y, 0.1, 0, length_includes_head=True, # head_width=0.03, head_length=0.02) ax1.text(0.139, 0.65, &quot;U = const&quot;) ax1.text(0.72, 0.7, &quot;p = 0 bar&quot;) ax1.text(0.45, 0.78, &quot;no slip&quot;) ax1.axis(&#39;off&#39;) plt.savefig(&quot;BCs.png&quot;, dpi = 300) .",
            "url": "https://simsisim.github.io/sims-blog/matplotlib/2021/02/09/drawShapes.html",
            "relUrl": "/matplotlib/2021/02/09/drawShapes.html",
            "date": " • Feb 9, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Layers in Keras",
            "content": "import tensorflow as tf from tensorflow import keras import numpy as np . VGG16 . vgg16 = tf.keras.applications.VGG16(include_top = False, weights = &quot;imagenet&quot;, input_tensor = tf.keras.layers.Input(shape = (224,224,3))) . Loop over layers, layer name . for layer in vgg16.layers: print (layer.name, &quot;: &quot;, layer) . input_2 : &lt;tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f0f47f9af10&gt; block1_conv1 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47f884d0&gt; block1_conv2 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47f88c10&gt; block1_pool : &lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f0f64271b10&gt; block2_conv1 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f8427fc90&gt; block2_conv2 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47fa92d0&gt; block2_pool : &lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f0f47faec90&gt; block3_conv1 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47f94050&gt; block3_conv2 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47fb0810&gt; block3_conv3 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47f868d0&gt; block3_pool : &lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f0f47f97890&gt; block4_conv1 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47fb8bd0&gt; block4_conv2 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47f96490&gt; block4_conv3 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47fa7ed0&gt; block4_pool : &lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f0f47f7b650&gt; block5_conv1 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47f9e910&gt; block5_conv2 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47f6e1d0&gt; block5_conv3 : &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47f70b90&gt; block5_pool : &lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f0f47f72990&gt; . for idx in range(len(vgg16.layers)): print(vgg16.get_layer(index = idx).name) . input_2 block1_conv1 block1_conv2 block1_pool block2_conv1 block2_conv2 block2_pool block3_conv1 block3_conv2 block3_conv3 block3_pool block4_conv1 block4_conv2 block4_conv3 block4_pool block5_conv1 block5_conv2 block5_conv3 block5_pool . Get first 4 layers . vgg16 = tf.keras.applications.VGG16(include_top = False, weights = &quot;imagenet&quot;, input_tensor = tf.keras.layers.Input(shape = (224,224,3))) print(vgg16.layers[1].input_shape) # print output shape print(vgg16.layers[1].output_shape) # weight matrix print(vgg16.layers[1].get_weights) # layer name print(vgg16.layers[1].name) # input tensor print(vgg16.layers[1].input) # output tensor print(vgg16.layers[1].output) . (None, 224, 224, 3) (None, 224, 224, 64) &lt;bound method Layer.get_weights of &lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0f47f1b410&gt;&gt; block1_conv1 Tensor(&#34;input_4:0&#34;, shape=(None, 224, 224, 3), dtype=float32) Tensor(&#34;block1_conv1/Relu_3:0&#34;, shape=(None, 224, 224, 64), dtype=float32) . Grab layer after name . vgg16 = tf.keras.applications.VGG16(include_top = False, weights = &quot;imagenet&quot;, input_tensor = tf.keras.layers.Input(shape = (224,224,3))) vgg16.get_layer(&#39;block3_conv1&#39;).output . &lt;tf.Tensor &#39;block3_conv1/Relu_1:0&#39; shape=(None, 56, 56, 256) dtype=float32&gt; . Build a model based on VGG16 . vgg16 = tf.keras.applications.VGG16(include_top = False, weights = &quot;imagenet&quot;, input_tensor = tf.keras.layers.Input(shape = (224,224,3))) model_output = vgg16.get_layer(&quot;block3_conv1&quot;).output new_model = tf.keras.models.Model(inputs=vgg16.input, outputs=model_output) .",
            "url": "https://simsisim.github.io/sims-blog/keras/2021/02/08/keras-layers.html",
            "relUrl": "/keras/2021/02/08/keras-layers.html",
            "date": " • Feb 8, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Commands",
            "content": "1.Execute jupyter notebook in command line . jupyter nbconvert --to notebook --inplace --execute my-file.ipynb . 2. Convert jupyter notebook to python script . jupyter nbconvert --to script my-file.ipynb . 3. Include image in jupyter notebook . ![](images/calculator_erased.jpg) . . from IPython.display import Image Image(url=&quot;images/calculator_erased.jpg&quot;, width=200) . 4. Rename *.py filename . import os filename = &quot;2020-12-29-build_dataset.py&quot; new_filename = (filename.split(sep = &quot;-&quot;)[-1]).split(sep = &quot;.&quot;)[0] + &quot;.py&quot; os.rename(filename, new_filename) . 4. Markdown guide . https https://about.gitlab.com/handbook/markdown-guide/ .",
            "url": "https://simsisim.github.io/sims-blog/commands/2020/12/22/Commands.html",
            "relUrl": "/commands/2020/12/22/Commands.html",
            "date": " • Dec 22, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Create TFRecords from ny files",
            "content": "import numpy as np import sys import tensorflow as tf import matplotlib.pyplot as plt from tensorflow import keras from functools import partial import IPython.display as display print(&quot;finish&quot;) tf.__version__ . finish . &#39;2.3.0&#39; . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . import glob from random import shuffle train_file_path = &quot;/content/drive/My Drive/datasets/cfd_tum/train/*.npz&quot; train_files_npz = glob.glob(train_file_path) test_file_path = &quot;/content/drive/My Drive/datasets/cfd_tum/test/*.npz&quot; test_files_npz = glob.glob(test_file_path) list_filenames = test_files_npz #list_filenames = list_filenames[:10] . tfrecords_train_name = &quot;/content/drive/My Drive/datasets/cfd_tum/cfdTUM-Training.tfrecords&quot; tfrecords_test_name = &quot;/content/drive/My Drive/datasets/cfd_tum/cfdTUM-Test.tfrecords&quot; tfrecords_filename = tfrecords_test_name def _create_byte_feature(value): value = value.numpy() return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value])) with tf.io.TFRecordWriter(tfrecords_filename) as writer: for filename in list_filenames: data = np.load(filename) raw_data = data[&quot;a&quot;] b_vel_x = np.reshape(raw_data[0], [-1, 1]).squeeze() b_vel_y = np.reshape(raw_data[1], [-1, 1]).squeeze() b_geo = np.reshape(raw_data[2], [-1, 1]).squeeze() p_vel_x = np.reshape(raw_data[3], [-1, 1]).squeeze() p_vel_y = np.reshape(raw_data[4], [-1, 1]).squeeze() p_press = np.reshape(raw_data[5], [-1, 1]).squeeze() b_vel_x = tf.io.serialize_tensor(b_vel_x) b_vel_y = tf.io.serialize_tensor(b_vel_y) b_geo = tf.io.serialize_tensor(b_geo) p_vel_x = tf.io.serialize_tensor(p_vel_x) p_vel_y = tf.io.serialize_tensor(p_vel_y) p_press = tf.io.serialize_tensor(p_press) feature = {&quot;b_vel_x&quot;: _create_byte_feature(b_vel_x), &quot;b_vel_y&quot;: _create_byte_feature(b_vel_y), &quot;b_geo&quot;: _create_byte_feature(b_geo), &quot;p_vel_x&quot;: _create_byte_feature(p_vel_x), &quot;p_vel_y&quot;: _create_byte_feature(p_vel_y), &quot;p_press&quot;: _create_byte_feature(p_press) } example_message = tf.train.Example(features=tf.train.Features(feature=feature)) writer.write(example_message.SerializeToString()) writer.close() print(&quot;Finish&quot;) . Finish . #feature_description = {&#39;b_vel_x&#39;: tf.io.FixedLenFeature([], tf.string), # &#39;b_vel_y&#39;: tf.io.FixedLenFeature([], tf.string), # &#39;b_geo&#39;: tf.io.FixedLenFeature([], tf.string), # &#39;p_vel_x&#39;: tf.io.FixedLenFeature([], tf.string), # &#39;p_vel_y&#39;: tf.io.FixedLenFeature([], tf.string), # &#39;pressure&#39;: tf.io.FixedLenFeature([], tf.string) # } def _parse_tensor(exp): exp = tf.io.parse_tensor(exp, out_type=tf.float64) return (tf.reshape(exp, (128, 128, 1))) def _parse_image(example): feature_description = { &#39;b_vel_x&#39;: tf.io.FixedLenFeature([], tf.string), &#39;b_vel_y&#39;: tf.io.FixedLenFeature([], tf.string), &#39;b_geo&#39;: tf.io.FixedLenFeature([], tf.string), &#39;p_vel_x&#39;: tf.io.FixedLenFeature([], tf.string), &#39;p_vel_y&#39;: tf.io.FixedLenFeature([], tf.string), &#39;p_press&#39;: tf.io.FixedLenFeature([], tf.string) } example = tf.io.parse_single_example(example, feature_description) #list_exp = list(example[&quot;b_geo&quot;], example[&quot;b_vel_x&quot;], example[&quot;b_vel_y&quot;], example[&quot;p_vel_x&quot;], example[&quot;p_vel_y&quot;], example[&quot;pressure&quot;]) #for j in list_exp: # geo = _parse_tensor(j) b_geo = example[&quot;b_geo&quot;] b_geo = tf.io.parse_tensor(b_geo, out_type=tf.float64) b_geo = tf.reshape(b_geo, (128, 128, 1)) b_velx = example[&quot;b_vel_x&quot;] b_velx = tf.io.parse_tensor(b_velx, out_type=tf.float64) b_velx = tf.reshape(b_velx, (128, 128, 1)) b_vely = example[&quot;b_vel_y&quot;] b_vely = tf.io.parse_tensor(b_vely, out_type=tf.float64) b_vely = tf.reshape(b_vely, (128, 128, 1)) p_velx = example[&quot;p_vel_x&quot;] p_velx = tf.io.parse_tensor(p_velx, out_type=tf.float64) p_velx = tf.reshape(p_velx, (128, 128, 1)) p_vely = example[&quot;p_vel_y&quot;] p_vely = tf.io.parse_tensor(p_vely, out_type=tf.float64) p_vely = tf.reshape(p_vely, (128, 128, 1)) p_press = example[&quot;p_press&quot;] p_press = tf.io.parse_tensor(p_press, out_type=tf.float64) p_press = tf.reshape(p_vely, (128, 128, 1)) return b_geo, b_velx, b_vely, p_velx, p_vely, p_press def load_dataset(filename): dataset = tf.data.TFRecordDataset(tfrecords_filename) dataset = dataset.map(_parse_image) return dataset def get_dataset(filename, BATCH_SIZE): dataset = load_dataset(filename) dataset = dataset.shuffle(2048) #dataset = dataset.prefetch() dataset = dataset.batch(BATCH_SIZE) return dataset BATCH_SIZE = 12 dataset = get_dataset(filename, BATCH_SIZE) b_geo, b_velx, b_vely, p_velx, p_vely, p_pressure= next(iter(dataset)) #b_velx print(&quot;Finish&quot;) . Finish . for i in range(3): fig = plt.figure(figsize = (10, 10)) ax1 = fig.add_subplot(231) ax1 = ax1.imshow(b_geo[i, :, :, 0]) plt.colorbar(ax1) ax2 = fig.add_subplot(232) ax2 = ax2.imshow(b_velx[i, :, :, 0]) plt.colorbar(ax2) ax3 = fig.add_subplot(233) ax3 = ax3.imshow(b_vely[i, :, :, 0]) plt.colorbar(ax3) ax4 = fig.add_subplot(234) ax4 = ax4.imshow(p_velx[i, :, :, 0]) plt.colorbar(ax4) ax5 = fig.add_subplot(235) ax5 = ax5.imshow(p_vely[i, :, :, 0]) plt.colorbar(ax5) ax6 = fig.add_subplot(236) ax6 = ax6.imshow(p_pressure[i, :, :, 0]) plt.colorbar(ax6) .",
            "url": "https://simsisim.github.io/sims-blog/tfrecords/tensorflow/image%20processing/2020/12/21/createTFRecords_cfdTUM.html",
            "relUrl": "/tfrecords/tensorflow/image%20processing/2020/12/21/createTFRecords_cfdTUM.html",
            "date": " • Dec 21, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Write Images to TFRecords Format",
            "content": "import numpy as np import tensorflow as tf import glob . 1.TFRecord format . doesn&#39;t know anything about image formats | can save both dense arrays or image formats | in contrast to imread and imsave TF decouples reading/decoding and encoding/writting | . Steps . Encode the features as types compatible with tf.train.Example | This stores the raw image string feature, as well as the height, width, depth, and arbitrary label feature. | . 2. Creating a tf.train.Example message . Suppose you want to create a tf.train.Example message from existing data. In practice, the dataset may come from anywhere, but the procedure of creating the tf.train.Example message from a single observation will be the same: . Within each observation, each value needs to be converted to a tf.train.Feature containing one of the 3 compatible types, using one of the functions above . | You create a map (dictionary) from the feature name string to the encoded feature value produced in #1 . | The map produced in step 2 is converted to a Features message. . | . # with tf.train.Example. def _create_bytes_feature(value): &quot;&quot;&quot;Returns a bytes_list from a string / byte.&quot;&quot;&quot; if isinstance(value, type(tf.constant(0))): value = value.numpy() # BytesList won&#39;t unpack a string from an EagerTensor. return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value])) def _create_float_feature(value): &quot;&quot;&quot;Returns a float_list from a float / double.&quot;&quot;&quot; return tf.train.Feature(float_list=tf.train.FloatList(value=[value])) def _create_int64_feature(value): &quot;&quot;&quot;Returns an int64_list from a bool / enum / int / uint.&quot;&quot;&quot; return tf.train.Feature(int64_list=tf.train.Int64List(value=[value])) . #freedom02 = tf.keras.preprocessing.image.load_img(&quot;images/freedom.png&quot;) #freedom01_arr = tf.keras.preprocessing.image.img_to_array(freedom01)#image to array #freedom02_arr = tf.keras.preprocessing.image.img_to_array(freedom02) #freedom01_name = tf.keras.preprocessing.image.load_img(&quot;images/freedom.png&quot;)#load &amp; decode image #freedom02_name = tf.keras.preprocessing.image.load_img(&quot;images/freedom.png&quot;) #print(freedom01_arr.shape) . 3. Write a list of images to TFRecords . record_file = &quot;images/TFRecords/my-tfR.tfrecords&quot; #load all files in folder list_files = glob.glob(&quot;images/TFRecords/*.png&quot;) with tf.io.TFRecordWriter(record_file) as writer: for _, filename in enumerate(list_files): image_string = open(filename, &#39;rb&#39;).read()#reads each image in list in bytes format feature = {&quot;raw_image&quot;: _create_bytes_feature(image_string)} #create a feature named values which contains the whole bytes array tf_example = tf.train.Example(features=tf.train.Features(feature=feature))#creates an example writer.write(tf_example.SerializeToString()) #image_string . 4. Write a list of images/labels to TFRecords . record_file = &quot;images/TFRecords/my-tfR.tfrecords&quot; list_files = glob.glob(&quot;images/TFRecords/*.png&quot;) labels = [0, 1] images_labels = { list_files[0] : labels[0], list_files[1] : labels[1], } with tf.io.TFRecordWriter(record_file) as writer: for filename, label in images_labels.items(): image_string = open(filename, &#39;rb&#39;).read()#reads each image in list in bytes format feature = {&quot;raw_image&quot;: _create_bytes_feature(image_string),#create a feature named values which contains the whole bytes array &quot;label&quot;: _create_int64_feature(label) } #create a feature named label which contains 0 or 1 tf_example = tf.train.Example(features = tf.train.Features(feature=feature))#creates an example writer.write(tf_example.SerializeToString()) . 5. Write a list of images with additional information to TFRecords . To be able to read the TFRecord files additional information such as original size/shape of image must be retained. . record_file = &quot;images/TFRecords/my-tfR.tfrecords&quot; #load all files in folder list_files = glob.glob(&quot;images/TFRecords/*.png&quot;) with tf.io.TFRecordWriter(record_file) as writer: for _, filename in enumerate(list_files): image_string = open(filename, &#39;rb&#39;).read()#reads each image as byte string #image_shape = tf.image.decode_png(image_string).shape # size of image to be retained image_shape = (600, 400, 3) feature = {&quot;raw_image&quot;: _create_bytes_feature(image_string),#create a feature named values which contains the whole bytes array &#39;height&#39;: _create_int64_feature(image_shape[0]), &#39;width&#39; : _create_int64_feature(image_shape[1]), &quot;no_c&quot; : _create_int64_feature(image_shape[2]), }# tf_example = tf.train.Example(features=tf.train.Features(feature=feature))#creates an example writer.write(tf_example.SerializeToString()) . record_file = &quot;images/TFRecords/my-tfR-JPEG.tfrecords&quot; #load all files in folder list_files = glob.glob(&quot;images/TFRecords/*.jpg&quot;) with tf.io.TFRecordWriter(record_file) as writer: for _, filename in enumerate(list_files): image_string = open(filename, &#39;rb&#39;).read()#reads each image as byte string #image_shape = tf.image.decode_png(image_string).shape # size of image to be retained feature = {&quot;raw_image&quot;: _create_bytes_feature(image_string),#create a feature named values which contains the whole bytes array &#39;height&#39;: _create_int64_feature(image_shape[0]), &#39;width&#39; : _create_int64_feature(image_shape[1]), &quot;no_c&quot; : _create_int64_feature(image_shape[2]), }# tf_example = tf.train.Example(features=tf.train.Features(feature=feature))#creates an example writer.write(tf_example.SerializeToString()) . References: . https://planspace.org/20170403-images_and_tfrecords/ . https://gist.github.com/MathiasGruber/8debc802464a48efc8c22a2064e0bf78 . https://www.tensorflow.org/tutorials/load_data/tfrecord . https://machinelearningmastery.com/how-to-load-convert-and-save-images-with-the-keras-api/ .",
            "url": "https://simsisim.github.io/sims-blog/tfrecords/tensorflow/image%20processing/2020/12/21/Write_TFRecords.html",
            "relUrl": "/tfrecords/tensorflow/image%20processing/2020/12/21/Write_TFRecords.html",
            "date": " • Dec 21, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Read Images from TFRecords Format",
            "content": "import numpy as np import tensorflow as tf import glob %matplotlib inline . 1. TFRecord Format . doesn&#39;t know anything about image formats | can save both dense arrays or image formats | in contrast to imread and imsave TF decouples reading/decoding and encoding/writting | . 2. Reading Unknown Data . raw_records = tf.data.TFRecordDataset(&quot;images/TFRecords/my-tfR.tfrecords&quot;) for raw_record in raw_records.take(1): print(&quot;&quot;) #example = tf.train.Example() #example.ParseFromString(raw_record.numpy()) #example . . 3. TFRecord format (PNG raw file) . raw_image_dataset = tf.data.TFRecordDataset(&quot;images/TFRecords/my-tfR.tfrecords&quot;) image_feature_description = { &#39;height&#39;: tf.io.FixedLenFeature([], tf.int64), &#39;width&#39;: tf.io.FixedLenFeature([], tf.int64), &#39;no_c&#39;: tf.io.FixedLenFeature([], tf.int64), &#39;raw_image&#39;: tf.io.FixedLenFeature([], tf.string), } def _parse_image_function(example_proto): # Parse the input tf.train.Example proto using the dictionary above. example = tf.io.parse_single_example(example_proto,image_feature_description) raw_image = example[&quot;raw_image&quot;]#.numpy() #this is a tensor with bytes raw_image = tf.io.decode_png(raw_image,3) # this is a tensor with float32 shape_h = example[&quot;height&quot;] shape_w = example[&quot;width&quot;] no_c = example[&quot;no_c&quot;] #raw_image = tf.reshape(raw_image, [400, 600,3]) #raw_image = tf.cast(raw_image, tf.float32) return raw_image parsed_image_dataset = raw_image_dataset.map(_parse_image_function) parsed_image_dataset . &lt;MapDataset shapes: (None, None, 3), types: tf.uint8&gt; . for image in parsed_image_dataset.take(1): print(image.shape) . (600, 400, 3) . 4. TFRecord format (JPEG raw file) . def _parse_image_fct(example_proto): image_feature_description = { &#39;height&#39;: tf.io.FixedLenFeature([], tf.int64), &#39;width&#39;: tf.io.FixedLenFeature([], tf.int64), &#39;no_c&#39;: tf.io.FixedLenFeature([], tf.int64), &#39;raw_image&#39;: tf.io.FixedLenFeature([], tf.string), } # Parse the input tf.train.Example proto using the dictionary above. example = tf.io.parse_single_example(example_proto,image_feature_description) raw_image = example[&quot;raw_image&quot;] #this is a tensor with bytes raw_image = tf.io.decode_jpeg(contents = raw_image, channels = 0) shape_h = example[&quot;height&quot;] shape_w = example[&quot;width&quot;] no_c = example[&quot;no_c&quot;] #print(shape_h, shape_w, no_c) #raw_image = tf.reshape(raw_image, [shape_h, shape_w, no_c]) raw_image = tf.cast(raw_image, tf.float32) return raw_image #parsed_image_dataset = raw_image_dataset.map(_parse_image_function) def load_dataset(filename): dataset = tf.data.TFRecordDataset(filename) dataset = dataset.map(_parse_image_fct) return dataset def get_dataset(filename, BATCH_SIZE): dataset = load_dataset(filename) dataset = dataset.shuffle(2048) #dataset = dataset.prefetch() dataset = dataset.batch(BATCH_SIZE) return dataset BATCH_SIZE = 2 filename = &quot;images/TFRecords/my-tfR-JPEG.tfrecords&quot; dataset = get_dataset(filename, BATCH_SIZE) tfR_image = next(iter(dataset)) . for i in range(2): fig = plt.figure(figsize = (10, 10)) ax1 = fig.add_subplot(212) ax1 = ax1.imshow(tfR_image[i, :, :, :]/255.) plt.colorbar(ax1) .",
            "url": "https://simsisim.github.io/sims-blog/tfrecords/tensorflow/image%20processing/2020/12/21/Read_TFRecords.html",
            "relUrl": "/tfrecords/tensorflow/image%20processing/2020/12/21/Read_TFRecords.html",
            "date": " • Dec 21, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Image Processing Dense Array, JPEG, PNG",
            "content": "Images are dense matrixes, and have a certain numbers of rows and columns. They can have 1 (grey) or 3 (RGB) or 4 (RGB + alpha-transparency) channels. . The dimension of the image matrix is ( height, width, channels). . import numpy as np import matplotlib.pyplot as plt import matplotlib.image as mpimg from PIL import Image import cv2 from sys import getsizeof import tensorflow as tf . 1. Load image files (.jpg, .png, .bmp, .tif) . using PIL | using matplotlib: reads image as RGB | using cv2 : reads image as BRG | . imread: reads a file from disk and decodes it | imsave: encodes a image and writes it to a file on disk | . #image = Image.open(&quot;images/freedom.png&quot;) #plt.show(image) . Load image using Matplotlib . The Matplotlib image tutorial recommends using matplotlib.image.imread to read image formats from disk. This function will automatically change image array values to floats between zero and one, and it doesn&#39;t give any other options about how to read the image. . imshow works on 0-1 floats &amp; 0-255 uint8 values | It doesn&#39;t work on int! | . image = mpimg.imread(&quot;images/freedom.png&quot;) plt.imshow(image) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f8bd8cfd5d0&gt; . print(image.dtype) freedom_array_uint8 = (image*255).astype(np.uint8) #convert to 0-255 values . float32 . Load image using OpenCV . image = cv2.imread(&quot;images/freedom.png&quot;) #OpenCV uses BGR as its default colour order for images, matplotlib uses RGB RGB_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)# cv2.cvtColor() method is used to convert an image from one color space to another plt.imshow(RGB_image) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f8bd8beb3d0&gt; . For this image, the matrix will have 600 x 400 x 3 = 720,000 values. Each value is an unsigned 8-bit integer, in total 720,000 bytes. . Using unsigned 8-bit integers (256 possible values) for each value in the image array is enough for displaying images to humans. But when working with image data, it isn&#39;t uncommon to switch to 32-bit floats, for example. This increases tremendously the size of the data. . By loading the image files we can save them as arrays. Typical array operations can be performed on them. . print (RGB_image.shape, RGB_image.dtype) . (600, 400, 3) uint8 . Load image using keras.preprocessing.image . load_img(image): loads and decodes image | img_to_array(image) | . image_keras = tf.keras.preprocessing.image.load_img(&quot;images/freedom.png&quot;) # loads and decodes image print(type(image_keras)) print(image_keras.format) print(image_keras.mode) print(image_keras.size) #image_keras.show() . &lt;class &#39;PIL.Image.Image&#39;&gt; None RGB (400, 600) . 2. Image Processing . Dense Array . One way to store complete raster image data is by serializing a NumPy array to disk. . image04npy = 720,128 bytes . The file image04npy has 128 more bytes than the one required to store the array values. Those extra bytes specify things like the array shape/dimensions. . np.save(&quot;images/freedom.npy&quot;, RGB_image) freedomnpy = np.load(&#39;images/freedom.npy&#39;) print(&quot;Size of array:&quot;, freedomnpy.nbytes) print(&quot;Size of disk:&quot;, getsizeof(freedomnpy)) . Size of array: 720000 Size of disk: 720128 . Storing one pixels takes several bytes.There are two main options for saving images: whether to lose some information while saving, or not. . JPG format . JPEG is lossy by deflaut . | When saving an image as $*$.JPEG and read from it again, it is not necessary to get back the same values . | The &quot;image04_jpg.jpg&quot; has 6.3 kB, less than the 7 % of $*$.npy file that generated it . | cv2.IMWRITE_JPEG_QUALITY is between (0, 100), and allows to save losseless . | . cv2.imwrite(&quot;images/freedom_jpg.jpg&quot;, freedomnpy, [cv2.IMWRITE_JPEG_QUALITY, 0]) freedom_jpg = cv2.imread(&quot;images/freedom_jpg.jpg&quot;) plt.imshow(freedom_jpg) . &lt;matplotlib.image.AxesImage at 0x7f8bd8b86c90&gt; . PNG format . PNG is lossless . | When saving an image as $*$.PNG and read from it again one gets the same value backs . | cv2.IMWRITE_PNG_COMPRESSION is between (0, 1): bigger file, slower compression . | freedom_png.png = 721.8 kB, close to freedomnpy . | . cv2.imwrite(&quot;images/freedom_png.png&quot;, freedomnpy, [cv2.IMWRITE_PNG_COMPRESSION, 0]) freedom_png = cv2.imread(&quot;images/freedom_png.png&quot;) plt.imshow(freedom_png) . &lt;matplotlib.image.AxesImage at 0x7f8bd8b049d0&gt; . References: . https://planspace.org/20170403-images_and_tfrecords/ . https://subscription.packtpub.com/book/application_development/9781788474443/1/ch01lvl1sec14/saving-images-using-lossy-and-lossless-compression . https://www.tensorflow.org/tutorials/load_data/tfrecord . https://machinelearningmastery.com/how-to-load-convert-and-save-images-with-the-keras-api/ .",
            "url": "https://simsisim.github.io/sims-blog/image%20processing/computer%20vision/2020/12/21/Image_Processing.html",
            "relUrl": "/image%20processing/computer%20vision/2020/12/21/Image_Processing.html",
            "date": " • Dec 21, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "A list of commands for Git on Github",
            "content": "1. Open Terminal . 2. Change the current working directory to your local repository . 3. Checking the status of the repository (go inside project folder) . git status . 4. Staging files (add files to the staging area) . touch test.py git add test.py #git add test01.py test02.py test03.py git add . # adds all files in the directory . git reset HEAD test.py #unstage a file that was commited . 5. Making commits . git commit -m &quot;Commit message&quot; # commit a file git log # list of all comits git checkout &lt;commit-hash&gt; # go back to a previous commited state git checkout master # go back to last commit . 6. Pushing changes to repository . git push origin . 7. Remove files . git rm test.py git commit -m &quot;remove test.py&quot; git rm -r my_folder #delete folder . 8. Add / Commit multiple files . git add . git commit -m &quot;m: my mesage flag&quot; . git commit -a -m &quot;m: my mesage flag&quot; . 9. Create a Github blog with fastpages . Create a new repository from fastpage https://github.com/fastai/fastpages/generate sims-coursera . | Follow the indication in Initial Setup file to generate and create secret and public keys . | Accept / Merge the pullrequest: https://github.com/simsisim/sims-coursera/pull/1 (3-4 min) . | Blog generated: https://github.com/simsisim/sims-coursera . | Customize blog title etc. by changing: https://github.com/simsisim/sims-coursera/blob/master/_config.yml . | 10. Git / Clone a new repository from Github to local . mkdir new-folder . | cd new-folder . | git init . | git clone https://github.com/new-folder.git . | 11. Ungit a folder . rm -Rf .git .gitignore . 11. References . https:https://www.notion.so/Introduction-to-Git-ac396a0697704709a12b6a0e545db049 . github:https://github.com/fastai/fastpages . . .",
            "url": "https://simsisim.github.io/sims-blog/github/commands/2020/12/20/Intro_to_Git.html",
            "relUrl": "/github/commands/2020/12/20/Intro_to_Git.html",
            "date": " • Dec 20, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "Basic of Computer Vision",
            "content": "print(&quot;This is a test&quot;) . This is a test .",
            "url": "https://simsisim.github.io/sims-blog/computer%20vision/image%20processing/coursera/2020/12/20/Basic_of_Computer_Vision.html",
            "relUrl": "/computer%20vision/image%20processing/coursera/2020/12/20/Basic_of_Computer_Vision.html",
            "date": " • Dec 20, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://simsisim.github.io/sims-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post15": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://simsisim.github.io/sims-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://simsisim.github.io/sims-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://simsisim.github.io/sims-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}