{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Images to TFRecords Format\n",
    "> Image Processing Write Images to TFRecords Format\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [TFRecords, Tensorflow, Image Processing]\n",
    "- image: images/chart-preview.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TFRecord Format\n",
    "\n",
    " - doesn't know anything about image formats\n",
    " - can save both dense arrays or image formats\n",
    " - in contrast to imread and imsave TF  decouples reading/decoding and encoding/writting\n",
    " \n",
    "## 2. Steps\n",
    "  - Encode the features as types compatible with tf.train.Example\n",
    "  - This stores the raw image string feature, as well as the height, width, depth, and arbitrary label feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a tf.train.Example message\n",
    "\n",
    "Suppose you want to create a tf.train.Example message from existing data. In practice, the dataset may come from anywhere, but the procedure of creating the tf.train.Example message from a single observation will be the same:\n",
    "\n",
    "   - Within each observation, each value needs to be converted to a tf.train.Feature containing one of the 3 compatible types, using one of the functions above\n",
    "   \n",
    "   - You create a map (dictionary) from the feature name string to the encoded feature value produced in #1\n",
    "   \n",
    "   - The map produced in step 2 is converted to a Features message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.train.Example.\n",
    "\n",
    "def _create_bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _create_float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _create_int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freedom01 = tf.keras.preprocessing.image.load_img(\"images/freedom.png\")#load & decode image\n",
    "#freedom02 = tf.keras.preprocessing.image.load_img(\"images/freedom.png\")\n",
    "#freedom01_arr = tf.keras.preprocessing.image.img_to_array(freedom01)#image to array\n",
    "#freedom02_arr = tf.keras.preprocessing.image.img_to_array(freedom02)\n",
    "#freedom01_name = tf.keras.preprocessing.image.load_img(\"images/freedom.png\")#load & decode image\n",
    "#freedom02_name = tf.keras.preprocessing.image.load_img(\"images/freedom.png\")\n",
    "#print(freedom01_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write a List of Images to TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_file = \"images/TFRecords/my-tfR.tfrecords\"\n",
    "#load all files in folder\n",
    "list_files = glob.glob(\"images/TFRecords/*.png\")\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    for _, filename in enumerate(list_files):\n",
    "        image_string = open(filename, 'rb').read()#reads each image in list in bytes format\n",
    "        feature = {\"raw_image\": _create_bytes_feature(image_string)} #create a feature named values which contains the whole bytes array\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature=feature))#creates an example \n",
    "        writer.write(tf_example.SerializeToString())\n",
    "#image_string    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write a List of Images/Labels to TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write a List of Images with Additional Information to TFRecords\n",
    "\n",
    "To be able to read the TFRecord files additional information such as original size/shape of image must be retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "<https://planspace.org/20170403-images_and_tfrecords/>\n",
    "\n",
    "<https://gist.github.com/MathiasGruber/8debc802464a48efc8c22a2064e0bf78>\n",
    "\n",
    "<https://www.tensorflow.org/tutorials/load_data/tfrecord>\n",
    "\n",
    "<https://machinelearningmastery.com/how-to-load-convert-and-save-images-with-the-keras-api/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
